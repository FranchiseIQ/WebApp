name: Batch Generate FranchiseMap Locations

on:
  # Run daily at 2 AM UTC to continuously process location batches
  schedule:
    - cron: '0 2 * * *'  # Every day at 2:00 AM UTC
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of brands per batch (default 50)'
        required: false
        default: '50'

permissions:
  contents: write

jobs:
  batch-process:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Create Data Directory
        run: mkdir -p FranchiseMap/data/brands

      - name: Get Next Batch
        id: batch
        run: |
          pip install requests
          BATCH_SIZE=${{ github.event.inputs.batch_size || '50' }}
          python -m data_aggregation.pipelines.franchise.batch_processor --action get_batch --batch_size "$BATCH_SIZE"

      - name: Generate Locations for Batch
        if: steps.batch.outcome == 'success'
        run: |
          # Extract batch from processor output (between JSON markers)
          BATCH_SIZE=${{ github.event.inputs.batch_size || '50' }}
          BATCH=$(python -m data_aggregation.pipelines.franchise.batch_processor --action get_batch --batch_size "$BATCH_SIZE" 2>/dev/null | sed -n '/--- JSON OUTPUT START ---/,/--- JSON OUTPUT END ---/p' | sed '1d;$d' | python -c "import sys, json; data = json.load(sys.stdin); print(','.join(data['batch']))")
          echo "üîÑ Processing batch: $BATCH"

          if [ -z "$BATCH" ]; then
            echo "‚úÖ All brands already processed"
            exit 0
          fi

          # Generate locations - only pass supported arguments
          python -m data_aggregation.pipelines.franchise.generate_locations --batch "$BATCH"

          echo "‚úÖ Batch location generation complete"

      - name: Generate Updated Metadata
        run: |
          python -m data_aggregation.pipelines.franchise.build_brand_metadata

      - name: Get Batch Counts
        id: counts
        run: |
          # Extract location counts from manifest for the processed brands
          python3 <<'EOF'
          import json
          from pathlib import Path

          manifest_file = Path('FranchiseMap/data/manifest.json')
          if manifest_file.exists():
              with open(manifest_file) as f:
                  manifest = json.load(f)
                  counts = {item['ticker']: item['count'] for item in manifest}
                  print(json.dumps(counts))
          else:
              print("{}")
          EOF

      - name: Mark Batch Complete
        run: |
          BATCH_SIZE=${{ github.event.inputs.batch_size || '50' }}
          BATCH=$(python -m data_aggregation.pipelines.franchise.batch_processor --action get_batch --batch_size "$BATCH_SIZE" 2>/dev/null | sed -n '/--- JSON OUTPUT START ---/,/--- JSON OUTPUT END ---/p' | sed '1d;$d' | python -c "import sys, json; data = json.load(sys.stdin); print(','.join(data['batch']))")

          if [ -z "$BATCH" ]; then
            echo "‚ÑπÔ∏è  No batch to mark complete (all brands processed)"
            exit 0
          fi

          COUNTS=$(python3 -c "import json; from pathlib import Path; m = Path('FranchiseMap/data/manifest.json'); data = json.load(open(m)) if m.exists() else []; print(json.dumps({item['ticker']: item['count'] for item in data}))")
          python -m data_aggregation.pipelines.franchise.batch_processor --action complete_batch --batch "$BATCH" --counts "$COUNTS"

      - name: Upload Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: franchise-data-batch
          path: FranchiseMap/data/
          retention-days: 7

      - name: Commit and Push Changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          git add FranchiseMap/data/
          git add data_aggregation/processed_brands.txt

          # Check if there are changes
          if git diff --staged --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit."
            exit 0
          fi

          # Get batch information for commit message
          BATCH_INFO=$(python -m data_aggregation.pipelines.franchise.batch_processor --action get_batch --batch_size ${{ github.event.inputs.batch_size }} 2>/dev/null | sed -n '/--- JSON OUTPUT START ---/,/--- JSON OUTPUT END ---/p' | sed '1d;$d' | python -c "import sys, json; data = json.load(sys.stdin); print(f'{len(data[\"batch\"])} brands processed - {data[\"remaining\"]} remaining')" || echo "batch generation")

          git commit -m "chore: Generate FranchiseMap locations for batch [$BATCH_INFO] [skip ci]"

          # Safely push to current branch
          CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
          echo "üì§ Pushing to branch: $CURRENT_BRANCH"

          if git fetch origin "$CURRENT_BRANCH" 2>/dev/null; then
            git merge -X ours "origin/$CURRENT_BRANCH" || {
              echo "‚ö†Ô∏è  Merge conflict detected, using local version"
              git merge -X ours "origin/$CURRENT_BRANCH" || true
            }
          fi

          if git push origin "$CURRENT_BRANCH"; then
            echo "‚úÖ Batch generation results pushed successfully"
          else
            echo "‚ùå Error pushing changes, but data is valid"
            exit 1
          fi

      - name: Enrich Location Data with Addresses
        run: |
          echo "üìç Enriching location data with addresses and details..."
          python3 << 'EOF'
          import json
          from pathlib import Path
          from time import sleep
          import requests

          # Process all location files and add address data
          data_dir = Path('FranchiseMap/data/brands')
          if not data_dir.exists():
            print("‚ÑπÔ∏è No location data to enrich yet")
            exit(0)

          enriched_count = 0
          for brand_file in data_dir.glob('*.json'):
              try:
                  with open(brand_file, 'r', encoding='utf-8') as f:
                      brand_data = json.load(f)

                  # Add address info if missing
                  if isinstance(brand_data, list):
                      for location in brand_data:
                          if 'lat' in location and 'lng' in location:
                              # Try to get address via reverse geocoding (Nominatim)
                              if 'address' not in location or not location.get('address'):
                                  try:
                                      url = f"https://nominatim.openstreetmap.org/reverse?format=json&lat={location['lat']}&lon={location['lng']}"
                                      response = requests.get(url, timeout=10, headers={'User-Agent': 'FranchiseMap'})
                                      response.raise_for_status()
                                      data = response.json()

                                      # Extract address components
                                      address_parts = []
                                      if 'address' in data:
                                          addr = data['address']
                                          # Build readable address
                                          city = addr.get('city', addr.get('town', ''))
                                          state = addr.get('state', '')
                                          country = addr.get('country', '')

                                          if city:
                                              address_parts.append(city)
                                          if state:
                                              address_parts.append(state)

                                          location['address'] = ', '.join(address_parts)
                                          location['display_name'] = data.get('display_name', '')

                                      enriched_count += 1
                                      sleep(0.1)  # Rate limiting
                                  except Exception as e:
                                      print(f"‚ö†Ô∏è Could not geocode {location.get('name', 'Unknown')}: {e}")

                  # Save enriched data
                  with open(brand_file, 'w', encoding='utf-8') as f:
                      json.dump(brand_data, f, indent=2, ensure_ascii=False)

              except Exception as e:
                  print(f"‚ö†Ô∏è Error processing {brand_file.name}: {e}")

          print(f"‚úÖ Enriched {enriched_count} locations with address data")
          EOF

      - name: Validate Location Data Completeness
        run: |
          echo "üîç Validating location data completeness..."
          python3 << 'EOF'
          import json
          from pathlib import Path

          data_dir = Path('FranchiseMap/data/brands')
          stats = {
              'total_brands': 0,
              'total_locations': 0,
              'locations_with_address': 0,
              'locations_with_coords': 0,
              'locations_with_name': 0
          }

          if data_dir.exists():
              for brand_file in data_dir.glob('*.json'):
                  try:
                      with open(brand_file, 'r', encoding='utf-8') as f:
                          brand_data = json.load(f)

                      if isinstance(brand_data, list):
                          stats['total_brands'] += 1
                          for location in brand_data:
                              stats['total_locations'] += 1
                              if location.get('address'):
                                  stats['locations_with_address'] += 1
                              if 'lat' in location and 'lng' in location:
                                  stats['locations_with_coords'] += 1
                              if location.get('name'):
                                  stats['locations_with_name'] += 1
                  except Exception as e:
                      print(f"‚ö†Ô∏è Error validating {brand_file.name}: {e}")

          print("\nüìä Location Data Completeness Report:")
          print(f"   Total Brands: {stats['total_brands']}")
          print(f"   Total Locations: {stats['total_locations']}")
          print(f"   With Addresses: {stats['locations_with_address']} ({stats['locations_with_address']*100//max(stats['total_locations'], 1)}%)")
          print(f"   With Coordinates: {stats['locations_with_coords']} ({stats['locations_with_coords']*100//max(stats['total_locations'], 1)}%)")
          print(f"   With Names: {stats['locations_with_name']} ({stats['locations_with_name']*100//max(stats['total_locations'], 1)}%)")
          EOF

      - name: Queue Status
        run: |
          echo "üìä Batch Processing Status:"
          python -m data_aggregation.pipelines.franchise.batch_processor --action status

          # Check if there are remaining batches
          QUEUE_STATUS=$(python -m data_aggregation.pipelines.franchise.batch_processor --action status 2>/dev/null || echo "unknown")
          echo ""
          echo "‚ÑπÔ∏è Status: $QUEUE_STATUS"
          echo "üí° Next batch will be processed in the next scheduled run (daily at 2 AM UTC)"
